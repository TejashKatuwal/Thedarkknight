{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f23f635c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02cf685b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-1.23.4-cp310-cp310-win_amd64.whl (14.6 MB)\n",
      "     --------------------------------------- 14.6/14.6 MB 13.6 MB/s eta 0:00:00\n",
      "Installing collected packages: numpy\n",
      "Successfully installed numpy-1.23.4\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd75f67f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-1.5.1-cp310-cp310-win_amd64.whl (10.4 MB)\n",
      "     --------------------------------------- 10.4/10.4 MB 12.1 MB/s eta 0:00:00\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\acer\\desktop\\natural language processing\\nlp\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Collecting pytz>=2020.1\n",
      "  Downloading pytz-2022.6-py2.py3-none-any.whl (498 kB)\n",
      "     -------------------------------------- 498.1/498.1 kB 7.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\acer\\desktop\\natural language processing\\nlp\\lib\\site-packages (from pandas) (1.23.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\acer\\desktop\\natural language processing\\nlp\\lib\\site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Installing collected packages: pytz, pandas\n",
      "Successfully installed pandas-1.5.1 pytz-2022.6\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1b8eb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "490abd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(r\"C:\\Users\\Acer\\Desktop\\Natural Language Processing\\IMDB Dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "683e8f77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc6d11e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'sentiment'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "728e274e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       False\n",
       "sentiment    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cc3e1be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0edaae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>50000</td>\n",
       "      <td>50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>49582</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Loved today's show!!! It was a variety and not...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>25000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   review sentiment\n",
       "count                                               50000     50000\n",
       "unique                                              49582         2\n",
       "top     Loved today's show!!! It was a variety and not...  positive\n",
       "freq                                                    5     25000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "853d5941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    25000\n",
       "negative    25000\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa3f3e72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c69251",
   "metadata": {},
   "source": [
    "# TEXT NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce054711",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize,sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9619ee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import re,string,unicodedata\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.stem import LancasterStemmer,WordNetLemmatizer\n",
    "from sklearn.linear_model import LogisticRegression,SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b981032c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization of text\n",
    "tokenizers=ToktokTokenizer()\n",
    "#Setting English stopwords\n",
    "stopwords=nltk.corpus.stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1575a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def noiseremoval_text(text):\n",
    "  soup = BeautifulSoup(text, \"html.parser\")\n",
    "  text = soup.get_text()\n",
    "  text = re.sub('\\[[^]]*\\]', '', text)\n",
    "  return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de2bf0d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Acer\\Desktop\\Natural Language Processing\\NLP\\lib\\site-packages\\bs4\\__init__.py:435: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Apply function on review column\n",
    "data['review']=data['review'].apply(noiseremoval_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08643164",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. The filming tec...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. The filming tec...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d970ae7",
   "metadata": {},
   "source": [
    "# STEMMING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e7ea437",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Stemming the text\n",
    "def stemmer(text):\n",
    "    ps=nltk.porter.PorterStemmer()\n",
    "    text= ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "63d17e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply function on review column\n",
    "data['review']=data['review'].apply(stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3baf3c0",
   "metadata": {},
   "source": [
    "# REMOVING STOP WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f66aef1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords  \n",
    "from nltk.tokenize import word_tokenize  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7683d484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'itself', 'himself', 'weren', 'in', 'yours', 'mightn', 'themselves', 'now', \"won't\", 'yourselves', 'and', 'into', 'over', 'than', 'those', 'been', 'until', 'on', 't', 'his', 's', 'doing', 'once', 'being', \"mightn't\", 'd', 'any', 'he', 'other', 'yourself', 'when', 'be', \"aren't\", 'doesn', \"wasn't\", 'up', 'then', \"that'll\", 'from', 're', 'that', 'who', 'am', 'of', \"wouldn't\", 'they', 'theirs', \"she's\", 'down', 'ain', \"hadn't\", 'we', 'an', 'nor', 'whom', 'are', \"weren't\", 'him', 'most', 'isn', 'no', 'you', \"should've\", 'own', 'its', 'through', 'here', 'me', 'your', 'against', 'between', \"hasn't\", 'couldn', 'did', \"doesn't\", 'o', 'above', 'hadn', 'such', 'wasn', 'again', \"couldn't\", 'out', \"isn't\", \"haven't\", 'at', 'shan', 'some', 'can', 'y', 'few', 'during', 'because', \"it's\", 'it', 'our', 'these', 'all', 'what', 'aren', \"shouldn't\", 'after', 'ourselves', 'having', 'with', 'about', 'too', 'won', 'very', 'she', 'were', 'where', 'to', 'more', 'only', 'or', 'both', 'their', \"didn't\", 'them', 'should', 'how', 'each', 'mustn', 'under', \"you've\", 'will', 'shouldn', 'does', 'just', 'hasn', 'so', 'was', 'before', 'her', 'if', 'my', 'further', 'same', \"shan't\", \"you'll\", 'herself', \"don't\", 'has', 'why', 'by', 'off', 'didn', 'myself', 'ma', 'don', 'is', 'haven', 'have', 'which', 've', \"mustn't\", 'i', 'not', 'below', 'hers', 'as', 'for', 'm', 'wouldn', 'ours', 'there', \"you'd\", 'but', 'while', 'a', 'll', \"you're\", 'the', 'needn', 'do', \"needn't\", 'this', 'had'}\n"
     ]
    }
   ],
   "source": [
    "#set stopwords to english\n",
    "\n",
    "stop_wr=set(stopwords.words('english'))\n",
    "print(stop_wr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e9625081",
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing the stopwords\n",
    "def removing_stopwords(text, is_lower_case=False):\n",
    "    #Tokenization of text\n",
    "    tokenizers=ToktokTokenizer()\n",
    "    #Setting English stopwords\n",
    "    tokens = tokenizers.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filter_tokens = [token for token in tokens if token not in stop_wr]\n",
    "    else:\n",
    "        filter_tokens = [token for token in tokens if token.lower() not in stop_wr]\n",
    "    filtered_text = ' '.join(filter_tokens)    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da1c97ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Apply function on review column\n",
    "data['review']=data['review'].apply(removing_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "56e7032b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one review ha mention watch 1 oz episod ' hook...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wonder littl production. film techniqu veri un...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>thought thi wa wonder way spend time hot summe...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>basic ' famili littl boy ( jake ) think ' zomb...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>petter mattei ' \" love time money \" visual stu...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  one review ha mention watch 1 oz episod ' hook...  positive\n",
       "1  wonder littl production. film techniqu veri un...  positive\n",
       "2  thought thi wa wonder way spend time hot summe...  positive\n",
       "3  basic ' famili littl boy ( jake ) think ' zomb...  negative\n",
       "4  petter mattei ' \" love time money \" visual stu...  positive"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b3bed5",
   "metadata": {},
   "source": [
    "# TRAIN TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "42a03fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the dataset  \n",
    "#train dataset\n",
    "train_reviews_data=data.review[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8c200246",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test dataset\n",
    "\n",
    "test_reviews_data=data.review[30000:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248bfb45",
   "metadata": {},
   "source": [
    "# BAG OF WORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f458861f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BOW_cv_train: (30000, 4954557)\n",
      "BOW_cv_test: (20000, 4954557)\n"
     ]
    }
   ],
   "source": [
    "#Count vectorizer for bag of words\n",
    "cv=CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "cv_train=cv.fit_transform(train_reviews_data)\n",
    "#transformed test reviews\n",
    "cv_test=cv.transform(test_reviews_data)\n",
    "\n",
    "print('BOW_cv_train:',cv_train.shape)\n",
    "print('BOW_cv_test:',cv_test.shape)\n",
    "#vocab=cv.get_feature_names()-toget feature names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed73e661",
   "metadata": {},
   "source": [
    "# TF_IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "817f0b60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf_train: (30000, 4954557)\n",
      "Tfidf_test: (20000, 4954557)\n"
     ]
    }
   ],
   "source": [
    "#Tfidf vectorizer\n",
    "tf=TfidfVectorizer(min_df=0,max_df=1,use_idf=True,ngram_range=(1,3))\n",
    "#transformed train reviews\n",
    "tf_train=tf.fit_transform(train_reviews_data)\n",
    "#transformed test reviews\n",
    "tf_test=tf.transform(test_reviews_data)\n",
    "print('Tfidf_train:',tf_train.shape)\n",
    "print('Tfidf_test:',tf_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004f3911",
   "metadata": {},
   "source": [
    "# LABEL ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4dd20136",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 1)\n"
     ]
    }
   ],
   "source": [
    "#labeling the sentiment data\n",
    "label=LabelBinarizer()\n",
    "#transformed sentiment data\n",
    "sentiment_data=label.fit_transform(data['sentiment'])\n",
    "print(sentiment_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f360333e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=data.sentiment[:30000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a58f0aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=data.sentiment[30000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1c820d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n",
      "LogisticRegression(C=1, max_iter=500, random_state=42)\n"
     ]
    }
   ],
   "source": [
    "#training the model\n",
    "logistic=LogisticRegression(penalty='l2',max_iter=500,C=1,random_state=42)\n",
    "#Fitting the model for Bag of words\n",
    "lr_bow=logistic.fit(cv_train,train_data)\n",
    "print(lr_bow)\n",
    "#Fitting the model for tfidf features\n",
    "lr_tfidf=logistic.fit(tf_train,train_data)\n",
    "print(lr_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7cb3297c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'negative' 'negative' ... 'negative' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "#Predicting the model for bag of words\n",
    "lr_bow_predict=logistic.predict(cv_test)\n",
    "print(lr_bow_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "481f94b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'negative' 'negative' ... 'negative' 'positive' 'positive']\n"
     ]
    }
   ],
   "source": [
    "##Predicting the model for tfidf features\n",
    "lr_tfidf_predict=logistic.predict(tf_test)\n",
    "print(lr_tfidf_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de50129e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_bow_score : 0.74255\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for bag of words\n",
    "lr_bow_score=accuracy_score(test_data,lr_bow_predict)\n",
    "print(\"lr_bow_score :\",lr_bow_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a86cfd8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lr_tfidf_score : 0.7426\n"
     ]
    }
   ],
   "source": [
    "#Accuracy score for tfidf features\n",
    "lr_tfidf_score=accuracy_score(test_data,lr_tfidf_predict)\n",
    "print(\"lr_tfidf_score :\",lr_tfidf_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f64ad1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
